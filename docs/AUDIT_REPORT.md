# 项目功能性问题审计报告

本文档总结了对 GuardianBridge 项目进行代码审查后发现的主要功能性问题。这些问题按严重性排序，直接影响项目的核心功能、稳定性或与预期行为的一致性。

## 1. 严重：`fastText` 本地审核模型因 `NumPy` 版本不兼容而静默失败

-   **问题描述**: 项目的 `fastText` 审核模型与 `NumPy 2.0` 及更高版本不兼容。`requirements.txt` 文件虽然指定了 `numpy<2.0`，但如果用户环境中安装了更高版本的 NumPy，本地模型在预测时会抛出异常。
-   **影响**: 系统捕获此异常后，并**不会使服务崩溃或在启动时警告用户**，而是**静默地将所有本应由本地模型处理的请求回退到成本更高、速度更慢的 AI 审核**。这直接损害了项目“三段式智能审核”设计的核心价值——通过廉价、高效的本地模型过滤大量请求。用户在不知情的情况下，会承担额外的成本和延迟。
-   **相关文件**:
    -   `requirements.txt` (第 15 行)
    -   `ai_proxy/moderation/smart/ai.py` (第 340-358 行)
    -   `docs/NUMPY2_COMPATIBILITY.md`

## 2. 严重：应用启动时缺少关键环境检查

-   **问题描述**: 项目在启动时没有检查关键依赖（如 NumPy 和 fastText）的兼容性。
-   **影响**: 这加剧了第一个问题的影响。服务即使在不兼容的环境中也能成功启动，导致本地审核功能“带病运行”。用户只有在查看日志或发现成本异常增加时才可能意识到问题的存在。一个健壮的服务应该在启动时执行健康检查，并在检测到严重环境问题时失败并提供明确的错误信息。
-   **相关文件**: `ai_proxy/app.py`

## 3. 中等：对 `openai_responses` 格式的审核功能未实现

-   **问题描述**: 尽管项目声称支持 `openai_responses` 格式，但用于从中提取文本进行审核的函数 `_extract_from_openai_response` 并未完全实现，其中包含一个 `TODO` 注释。
-   **影响**: 这意味着对于 `openai_responses` 格式的请求，审核功能很可能部分或完全无效，因为无法正确提取所有需要审核的文本内容。这与项目声称的功能不符，并可能导致审核漏洞。
-   **相关文件**: `ai_proxy/transform/extractor.py` (第 106-109 行)

## 4. 中等：对 Gemini 流式请求的检测方式过于脆弱

-   **问题描述**: 系统通过检查请求 URL 中是否包含硬编码的字符串 `"streamGenerateContent"` 来判断一个 Gemini 请求是否为流式请求。
-   **影响**: 这种实现非常脆弱。如果上游的 Google Gemini API 更改其端点命名（例如，改为 `stream-generate-content`），此功能将立即失效，导致代理无法正确处理流式响应，从而破坏客户端的体验。
-   **相关文件**: `ai_proxy/proxy/router.py` (第 341-347 行)

## 5. 次要：`fastText` 概率计算在边缘情况下不准确

-   **问题描述**: `fasttext_predict_proba` 函数在解析模型预测结果时，如果违规标签 `__label__1` 没有出现在 top-k 的结果中，违规概率会默认为 `0.0`。
-   **影响**: 在某些边缘情况下（例如，多分类或模型置信度极低），这可能导致概率计算不准确，从而影响审核决策的精度。
-   **相关文件**: `ai_proxy/moderation/smart/fasttext_model.py` (第 189-193 行)

## 总结与建议

该项目是一个功能强大且设计精良的 AI 中间件，但在关键的本地审核功能上存在由环境兼容性引起的严重功能性缺陷。此外，一些功能的实现（如 Gemini 流式检测和 `openai_responses` 格式支持）存在脆弱或未完成的问题，可能导致在特定场景下功能失效。

建议优先解决 NumPy 兼容性问题和启动时环境检查，以确保其核心功能的稳定性和可靠性。