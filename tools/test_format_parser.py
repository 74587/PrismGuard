"""
æµ‹è¯•æ ¼å¼è§£æå™¨ - éªŒè¯æ–°æ·»åŠ çš„ Claude Code å’Œ OpenAI Codex è§£æå™¨
"""
import json
from ai_proxy.transform.formats.parser import detect_and_parse, get_parser


def test_claude_code_format():
    """æµ‹è¯• Claude Code æ ¼å¼è§£æ"""
    print("\n=== æµ‹è¯• Claude Code æ ¼å¼ ===")
    
    # Claude Code æ ¼å¼ç¤ºä¾‹
    body = {
        "prompt": "Analyze this code",
        "options": {
            "model": "claude-sonnet-4-5",
            "workingDirectory": "/path/to/project",
            "systemPrompt": "You are a code reviewer"
        }
    }
    
    path = "/api/query"
    headers = {}
    
    format_name, internal = detect_and_parse("auto", path, headers, body)
    
    if format_name:
        print(f"âœ… æ£€æµ‹åˆ°æ ¼å¼: {format_name}")
        print(f"   æ¨¡å‹: {internal.model}")
        print(f"   æ¶ˆæ¯æ•°: {len(internal.messages)}")
        print(f"   ç¬¬ä¸€æ¡æ¶ˆæ¯: {internal.messages[0].role} - {internal.messages[0].content[0].text[:50]}...")
    else:
        print("âŒ æœªèƒ½è¯†åˆ«æ ¼å¼")
    
    return format_name == "claude_code"


def test_openai_codex_format():
    """æµ‹è¯• OpenAI Codex/Completions æ ¼å¼è§£æ"""
    print("\n=== æµ‹è¯• OpenAI Codex æ ¼å¼ ===")
    
    # OpenAI Completions API æ ¼å¼ç¤ºä¾‹
    body = {
        "model": "text-davinci-003",
        "prompt": "Write a Python function to calculate fibonacci",
        "max_tokens": 100,
        "temperature": 0.7
    }
    
    path = "/v1/completions"
    headers = {}
    
    format_name, internal = detect_and_parse("auto", path, headers, body)
    
    if format_name:
        print(f"âœ… æ£€æµ‹åˆ°æ ¼å¼: {format_name}")
        print(f"   æ¨¡å‹: {internal.model}")
        print(f"   æ¶ˆæ¯æ•°: {len(internal.messages)}")
        print(f"   ç¬¬ä¸€æ¡æ¶ˆæ¯: {internal.messages[0].role} - {internal.messages[0].content[0].text[:50]}...")
    else:
        print("âŒ æœªèƒ½è¯†åˆ«æ ¼å¼")
    
    return format_name == "openai_codex"


def test_claude_chat_exclusion():
    """æµ‹è¯• Claude Chat æ ¼å¼æ’æ–¥ Claude Code"""
    print("\n=== æµ‹è¯• Claude Chat æ’æ–¥ Claude Code ===")
    
    # Claude Code æ ¼å¼ä¸åº”è¢« Claude Chat è¯†åˆ«
    body = {
        "prompt": "Test prompt",
        "options": {"model": "claude-sonnet-4-5"}
    }
    
    path = "/api/query"
    headers = {}
    
    parser = get_parser("claude_chat")
    can_parse = parser.can_parse(path, headers, body)
    
    if not can_parse:
        print("âœ… Claude Chat æ­£ç¡®æ’æ–¥äº† Claude Code æ ¼å¼")
    else:
        print("âŒ Claude Chat é”™è¯¯è¯†åˆ«äº† Claude Code æ ¼å¼")
    
    return not can_parse


def test_openai_chat_exclusion():
    """æµ‹è¯• OpenAI Chat æ ¼å¼æ’æ–¥ OpenAI Codex"""
    print("\n=== æµ‹è¯• OpenAI Chat æ’æ–¥ OpenAI Codex ===")
    
    # OpenAI Codex æ ¼å¼ä¸åº”è¢« OpenAI Chat è¯†åˆ«
    body = {
        "model": "text-davinci-003",
        "prompt": "Test prompt",
        "max_tokens": 100
    }
    
    path = "/v1/completions"
    headers = {}
    
    parser = get_parser("openai_chat")
    can_parse = parser.can_parse(path, headers, body)
    
    if not can_parse:
        print("âœ… OpenAI Chat æ­£ç¡®æ’æ–¥äº† OpenAI Codex æ ¼å¼")
    else:
        print("âŒ OpenAI Chat é”™è¯¯è¯†åˆ«äº† OpenAI Codex æ ¼å¼")
    
    return not can_parse


def test_format_conversion():
    """æµ‹è¯•æ ¼å¼è½¬æ¢"""
    print("\n=== æµ‹è¯•æ ¼å¼è½¬æ¢ ===")
    
    # æµ‹è¯• Claude Code -> OpenAI Chat è½¬æ¢
    print("\n1. Claude Code -> OpenAI Chat")
    
    claude_code_body = {
        "prompt": "Write a hello world program",
        "options": {
            "model": "claude-sonnet-4-5",
            "systemPrompt": "You are a helpful assistant"
        }
    }
    
    # è§£æ Claude Code æ ¼å¼
    claude_parser = get_parser("claude_code")
    internal = claude_parser.from_format(claude_code_body)
    
    # è½¬æ¢ä¸º OpenAI Chat æ ¼å¼
    openai_parser = get_parser("openai_chat")
    openai_body = openai_parser.to_format(internal)
    
    print(f"   åŸå§‹æ ¼å¼: Claude Code")
    print(f"   è½¬æ¢å: OpenAI Chat")
    print(f"   æ¶ˆæ¯æ•°: {len(openai_body.get('messages', []))}")
    print(f"   æ¨¡å‹: {openai_body.get('model')}")
    
    # æµ‹è¯• OpenAI Codex -> Claude Chat è½¬æ¢
    print("\n2. OpenAI Codex -> Claude Chat")
    
    codex_body = {
        "model": "text-davinci-003",
        "prompt": "Explain quantum computing",
        "max_tokens": 200
    }
    
    # è§£æ OpenAI Codex æ ¼å¼
    codex_parser = get_parser("openai_codex")
    internal = codex_parser.from_format(codex_body)
    
    # è½¬æ¢ä¸º Claude Chat æ ¼å¼
    claude_chat_parser = get_parser("claude_chat")
    claude_body = claude_chat_parser.to_format(internal)
    
    print(f"   åŸå§‹æ ¼å¼: OpenAI Codex")
    print(f"   è½¬æ¢å: Claude Chat")
    print(f"   æ¶ˆæ¯æ•°: {len(claude_body.get('messages', []))}")
    print(f"   æ¨¡å‹: {claude_body.get('model')}")
    
    return True


def test_auto_detection():
    """æµ‹è¯•è‡ªåŠ¨æ£€æµ‹åŠŸèƒ½"""
    print("\n=== æµ‹è¯•è‡ªåŠ¨æ ¼å¼æ£€æµ‹ ===")
    
    test_cases = [
        {
            "name": "OpenAI Chat",
            "path": "/v1/chat/completions",
            "headers": {},
            "body": {"model": "gpt-4", "messages": [{"role": "user", "content": "Hello"}]},
            "expected": "openai_chat"
        },
        {
            "name": "Claude Chat",
            "path": "/v1/messages",
            "headers": {"anthropic-version": "2023-06-01"},
            "body": {"model": "claude-3-5-sonnet-20241022", "messages": [{"role": "user", "content": [{"type": "text", "text": "Hello"}]}]},
            "expected": "claude_chat"
        },
        {
            "name": "Claude Code",
            "path": "/api/query",
            "headers": {},
            "body": {"prompt": "Test", "options": {"model": "claude-sonnet-4-5"}},
            "expected": "claude_code"
        },
        {
            "name": "OpenAI Codex",
            "path": "/v1/completions",
            "headers": {},
            "body": {"model": "text-davinci-003", "prompt": "Test", "max_tokens": 100},
            "expected": "openai_codex"
        }
    ]
    
    results = []
    for case in test_cases:
        format_name, internal = detect_and_parse("auto", case["path"], case["headers"], case["body"])
        success = format_name == case["expected"]
        results.append(success)
        
        status = "âœ…" if success else "âŒ"
        print(f"{status} {case['name']}: æœŸæœ› {case['expected']}, å®é™… {format_name}")
    
    return all(results)


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 60)
    print("æ ¼å¼è§£æå™¨æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    tests = [
        ("Claude Code æ ¼å¼è§£æ", test_claude_code_format),
        ("OpenAI Codex æ ¼å¼è§£æ", test_openai_codex_format),
        ("Claude Chat æ’æ–¥æµ‹è¯•", test_claude_chat_exclusion),
        ("OpenAI Chat æ’æ–¥æµ‹è¯•", test_openai_chat_exclusion),
        ("æ ¼å¼è½¬æ¢æµ‹è¯•", test_format_conversion),
        ("è‡ªåŠ¨æ£€æµ‹æµ‹è¯•", test_auto_detection)
    ]
    
    results = []
    for name, test_func in tests:
        try:
            result = test_func()
            results.append((name, result))
        except Exception as e:
            print(f"\nâŒ {name} å¤±è´¥: {e}")
            results.append((name, False))
    
    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status}: {name}")
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")
        return 1


if __name__ == "__main__":
    exit(main())